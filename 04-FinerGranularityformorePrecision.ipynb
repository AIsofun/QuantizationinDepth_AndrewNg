{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b108e49-64a5-4dd4-b676-bcf0bc8d9f3b",
   "metadata": {},
   "source": [
    "# L3-B - Linear Quantization II: Finer Granularity for more Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31041fc8-6953-4aef-8d71-6384cf23bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602710b-92ca-47f7-8eca-6d29acd7c986",
   "metadata": {},
   "source": [
    "## 一些必要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1902afa-6424-4573-a38b-84a69b2dfdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric(tensor, dtype = torch.int8):\n",
    "    scale = get_q_scale_symmetric(tensor, dtype)\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(tensor, scale, zero_point = 0, dtype=dtype)\n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090869b9-9470-4c6d-8202-3fa65b5f0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_scale_symmetric(tensor, dtype = torch.int8):\n",
    "    r_max = tensor.abs().max().item()\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "    return r_max/q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d50c742-b75a-412a-b6cc-51cdff519e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_dequantization(quantized_tensor, scale, zero_point):\n",
    "    return scale * (quantized_tensor.float() - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bcfc5e9-b70d-4777-8f01-535ef58af16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_with_scale_and_zero_point(\n",
    "    tensor, scale, zero_point, dtype=torch.int8):\n",
    "    scaled_and_shifted_tensor = tensor / scale + zero_point\n",
    "    \n",
    "    rounded_tensor = torch.round(scaled_and_shifted_tensor)\n",
    "    #最后一步是，确保我们的舍入张量在最小量化值和最大量化值之间\n",
    "    q_min = torch.iinfo(dtype).min#iInfo方法获取最小值和最大值\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "\n",
    "    q_tensor = rounded_tensor.clamp(q_min, q_max).to(dtype)#定义量化张量（使用to()函数转换为我们想要的量化数据类型）\n",
    "    return q_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7223bd-daa9-4a78-a786-3eed26871671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_error(original_tensor, dequantized_tensor, error_type=\"mse\"):\n",
    "    \"\"\"\n",
    "    计算量化误差的通用函数（支持 PyTorch 和 NumPy 张量）\n",
    "    \n",
    "    参数：\n",
    "        original_tensor      : 原始浮点张量 (torch.Tensor/np.ndarray)\n",
    "        dequantized_tensor   : 反量化后的重建张量 (与原始张量同类型同形状)\n",
    "        error_type          : 误差计算方式，可选 \"mse\"(默认) 或 \"mae\"\n",
    "    \n",
    "    返回：\n",
    "        量化误差值 (float)\n",
    "    \"\"\"\n",
    "    # 校验输入类型一致性\n",
    "    if type(original_tensor) != type(dequantized_tensor):\n",
    "        raise TypeError(\"原始张量与反量化张量类型必须一致\")\n",
    "\n",
    "    # 校验形状一致性\n",
    "    if original_tensor.shape != dequantized_tensor.shape:\n",
    "        raise ValueError(\"张量形状不匹配\")\n",
    "\n",
    "    # 自动检测计算框架\n",
    "    if isinstance(original_tensor, torch.Tensor):\n",
    "        lib = torch\n",
    "    elif isinstance(original_tensor, np.ndarray):\n",
    "        lib = np\n",
    "    else:\n",
    "        raise TypeError(\"仅支持 PyTorch 或 NumPy 张量\")\n",
    "\n",
    "    # 计算误差\n",
    "    diff = original_tensor - dequantized_tensor\n",
    "    if error_type == \"mse\":\n",
    "        error = lib.mean(diff ** 2)\n",
    "    elif error_type == \"mae\":\n",
    "        error = lib.mean(lib.abs(diff))\n",
    "    else:\n",
    "        raise ValueError(\"error_type 必须为 'mse' 或 'mae'\")\n",
    "\n",
    "    # 返回标量值\n",
    "    return error.item() if lib == torch else float(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6394e-7c5b-42fe-8403-e4f38e454415",
   "metadata": {},
   "source": [
    "## Per Tensor\n",
    "- Perform `Per Tensor` Symmetric Quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a343d0-05d8-4b94-bf73-3cedce838557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tensor\n",
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "843906ad-088c-469c-b5ad-4ebeb3cb96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor, scale = linear_q_symmetric(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bb6ad40-e17e-428d-957f-8db3c55b7112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 33,  -2, 127],\n",
       "        [ 16,  52, -32],\n",
       "        [  0, 119,  43]], dtype=torch.int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5451070-b5a2-41f8-b37b-fba9e87fcf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.737007681779035"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8974052c-20f4-4b27-a782-79ee38092287",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor, scale, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a38b8a-211b-4fae-b75e-01f219726e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 189.3213,  -11.4740,  728.6000],\n",
       "        [  91.7921,  298.3244, -183.5842],\n",
       "        [   0.0000,  682.7039,  246.6913]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e71f274-56a8-4b5d-983b-f5a85602d12b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_quantization_errors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 未实现的函数（TODO）\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_quantization_errors\u001b[49m(test_tensor, quantized_tensor,\n\u001b[0;32m      3\u001b[0m                          dequantized_tensor)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_quantization_errors' is not defined"
     ]
    }
   ],
   "source": [
    "# 未实现的函数（TODO）\n",
    "plot_quantization_errors(test_tensor, quantized_tensor,\n",
    "                         dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7a9e50-dd29-4313-8147-595619722da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization Error : 2.5091912746429443\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c418b19-a8c2-423c-a0ac-0a51f8b2a93c",
   "metadata": {},
   "source": [
    "## Per Channel\n",
    "- Implement `Per Channel` Symmetric Quantization\n",
    "- `dim` parameter decides if it needs to be along the rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163e9da2-ad27-4d00-aff9-3e2e317a50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric_per_channel(tensor,dim,dtype=torch.int8):\n",
    "\n",
    "\n",
    "\n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc85c659-3d4e-42b6-b5ad-14719de25440",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e501f0-87f9-439f-8129-7f82b03f7ad4",
   "metadata": {},
   "source": [
    "- `dim = 0`, along the rows\n",
    "- `dim = 1`, along the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38c4237-03a1-49a3-8103-c563ee74ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=0\n",
    "output_dim = test_tensor.shape[dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff6920ab-1a69-4a7b-b2e6-72ff1c5290be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dba228f4-1e0b-43eb-8bf5-1f8a1d5e4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = torch.zeros(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aae3dbc-fbbf-45e5-a272-96202f1193ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b909b-ff5f-4d68-9b4d-64fa23d5ea9a",
   "metadata": {},
   "source": [
    "- Iterate through each row to calculate its `scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "902b4426-cf47-40fb-babb-451c5a898e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([191.6000, -13.5000, 728.6000])\n",
      "tensor([  92.1400,  295.5000, -184.0000])\n",
      "tensor([  0.0000, 684.6000, 245.5000])\n"
     ]
    }
   ],
   "source": [
    "for index in range(output_dim):\n",
    "    sub_tensor = test_tensor.select(dim,index)\n",
    "    print(sub_tensor)\n",
    "    scale[index] = get_q_scale_symmetric(sub_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c02aa202-aa46-4a35-b624-e21731a3583b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7370, 2.3268, 5.3906])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d19923bd-264b-4a41-be33-31a742eea482",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_shape = [1] * test_tensor.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52648b0d-a4e0-42e2-864f-15c7b784d6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8175e4e9-56fe-4870-b21b-dfd5db10f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_shape[dim] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69811f28-7091-4f39-9818-e52fbeb58366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 1]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "682228d0-1410-4d97-8a86-f7d0abe04223",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = scale.view(scale_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6358478-9908-4a93-b299-c29e0306b359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.7370],\n",
       "        [2.3268],\n",
       "        [5.3906]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy to be used later\n",
    "copy_scale = scale\n",
    "\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190a0af-87ad-489c-b342-de9c1de2da4c",
   "metadata": {},
   "source": [
    "#### Understanding tensor by tensor division using `view` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fede31b-6b12-4f0f-9a26-d9f963bb1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb013874-ed41-4c94-b320-12723172b7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75da6f10-589a-4c12-aa89-31aac58aa5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor([1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca576be3-b2e9-4533-9517-9e491f64cfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  5, 10])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d16727d-6064-4430-9db5-7a692573c3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ccc9782-0d75-4b65-957e-fb044adc815f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.view(1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a3d998f-fa73-40ca-a150-84b078b3bdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternate way\n",
    "s.view(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df0db911-ad1e-4435-aa28-9115fbc31578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.view(-1,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad58615-a052-4b7e-acb5-70c03ad9950f",
   "metadata": {},
   "source": [
    "##### Along the row division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de686dc2-58df-45aa-83b0-0c56255a06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = torch.tensor([[1], [5], [10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72fcafb3-d803-46ab-973e-55c759341fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c0d05b4-d429-4cbd-bcca-aa81cd712b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000, 3.0000],\n",
       "        [0.8000, 1.0000, 1.2000],\n",
       "        [0.7000, 0.8000, 0.9000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c59d9-013c-4ebc-ace7-41eda63c36f3",
   "metadata": {},
   "source": [
    "##### Along the column division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "480c619e-cb2d-4df3-a962-aa4f72d2973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = torch.tensor([[1, 5, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "555bc713-3708-47ae-afc7-67dbe5cb92e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af03d8d5-9f57-486f-a60d-08b385e038e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.4000, 0.3000],\n",
       "        [4.0000, 1.0000, 0.6000],\n",
       "        [7.0000, 1.6000, 0.9000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec229c5e-c0fb-417a-80bf-3c5f0f22f653",
   "metadata": {},
   "source": [
    "#### Coming back to quantizing the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9db38bf7-5363-459b-b837-da359e9a56d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.7370],\n",
       "        [2.3268],\n",
       "        [5.3906]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the scale you got earlier\n",
    "scale = copy_scale\n",
    "\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78abe805-d8fd-4412-b0eb-c5211d8ab94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "191ca82f-8649-429e-8846-0e07edc325d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "    test_tensor, scale=scale, zero_point=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f45bfef6-0ce7-43bc-9f34-5e07871fa584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 33,  -2, 127],\n",
       "        [ 40, 127, -79],\n",
       "        [  0, 127,  46]], dtype=torch.int8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446a0dc-1a0f-4f19-b8b9-01dc3e01be56",
   "metadata": {},
   "source": [
    "- Now, put all this in `linear_q_symmetric_per_channel` function defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a313de2-8be9-4b91-a3ac-bdd3582ae6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric_per_channel(r_tensor, dim, dtype=torch.int8):\n",
    "    \n",
    "    output_dim = r_tensor.shape[dim]\n",
    "    # store the scales\n",
    "    scale = torch.zeros(output_dim)\n",
    "\n",
    "    for index in range(output_dim):\n",
    "        sub_tensor = r_tensor.select(dim, index)\n",
    "        scale[index] = get_q_scale_symmetric(sub_tensor, dtype=dtype)\n",
    "\n",
    "    # reshape the scale\n",
    "    scale_shape = [1] * r_tensor.dim()\n",
    "    scale_shape[dim] = -1\n",
    "    scale = scale.view(scale_shape)\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "        r_tensor, scale=scale, zero_point=0, dtype=dtype)\n",
    "   \n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "076125de-61ff-426e-899f-1743c2cd57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bdacc63b-c7b6-4b8b-ac47-b3cf5ede5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "### along the rows (dim = 0)\n",
    "quantized_tensor_0, scale_0 = linear_q_symmetric_per_channel(\n",
    "    test_tensor, dim=0)\n",
    "\n",
    "### along the columns (dim = 1)\n",
    "quantized_tensor_1, scale_1 = linear_q_symmetric_per_channel(\n",
    "    test_tensor, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24191ffc-6d8d-4b2e-897b-3c0f6b64e737",
   "metadata": {},
   "source": [
    "- Plot the quantization error for along the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08e1665e-8406-45b7-8be5-17a19ca43992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor_0 = linear_dequantization(\n",
    "    quantized_tensor_0, scale_0, 0)\n",
    "\n",
    "#plot_quantization_errors(test_tensor, quantized_tensor_0, dequantized_tensor_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddab7e6c-f1ea-4d89-9641-af46ffc19782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization Error : 1.8084441423416138\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor_0)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703509af-c7b7-4da1-a2a0-f634d1f346c9",
   "metadata": {},
   "source": [
    "- Plot the quantization error for along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "463a6cfb-3604-4595-a95a-41c99cd2a58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization Error : 1.0781488418579102\n"
     ]
    }
   ],
   "source": [
    "dequantized_tensor_1 = linear_dequantization(\n",
    "    quantized_tensor_1, scale_1, 0)\n",
    "\n",
    "#plot_quantization_errors(test_tensor, quantized_tensor_1, dequantized_tensor_1, n_bits=8)\n",
    "\n",
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor_1)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb369ed-5ea1-4924-8780-977ec607a0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
