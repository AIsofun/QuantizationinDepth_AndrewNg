{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a12a31f-5f18-460d-8221-a4bfe2c1611e",
   "metadata": {},
   "source": [
    "# L3-A - Linear Quantization II: Symmetric vs. Asymmetric Mode "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f25df-a8f8-44e6-b2ff-d5ca06ccefe8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "\n",
    "There are two modes in linear quantization: \n",
    "1. Asymmetric: We map $[r_{\\text{min}}, r_{\\text{max}}] \\to [q_{\\text{min}}, q_{\\text{max}}]$ \n",
    "   this is what we implemented in the previous lesson.\n",
    "\n",
    "2. Symmetric: We map $[-r_{\\text{min}}, r_{\\text{max}}] \\to [-q_{\\text{min}}, q_{\\text{max}}]$\n",
    "\n",
    "   where we can set $r_{\\text{max}}$ = max(|r_tensor|)\n",
    "\n",
    "   We don't need to use the zero point(z=0).\n",
    "\n",
    "   this happens because the floating-point range and the quantized range are symmetric with respect to zero.\n",
    "\n",
    "   Hence, we can simplify the equations to:\n",
    "\n",
    "$$\n",
    " \\begin{cases}\n",
    " q = int(round(r/s))\\\\\n",
    " s =r_{\\text{max}} / q_{\\text{max}}\\\\\n",
    " \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b1b4a8-ae39-444b-8c37-d4357aa7f0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/hwgeng/miniconda3/envs/python310/lib/python3.10/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022705aa-8bb6-4ad6-907f-39b0b3650935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96cf059-97c1-440c-a23f-9ef40cf11f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de7e0fa-665b-472b-90d5-b3e8e362fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_scale_symmetric(tensor, dtype = torch.int8):\n",
    "    r_max = tensor.abs().max().item()\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "    return r_max/q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86d84d2-3b5f-4b11-a1d0-7610d93a693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.randn((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91759250-02ab-4495-b71f-11342731ddf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2720, -0.6343, -0.7974, -0.2175],\n",
       "        [-0.2736,  0.5604,  0.1311, -0.5916],\n",
       "        [ 2.4399,  0.6490, -0.0484, -0.2387],\n",
       "        [-1.3137, -0.5375,  0.7477,  0.2384]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d3d02a-5b1a-47d1-bdf0-0aa8ecf538e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = get_q_scale_symmetric(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734cec21-d2b3-4b17-a1ab-86697fb59180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019211733435082624"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cff376e-c4b4-481f-a2f3-0fe510d38690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_with_scale_and_zero_point(\n",
    "    tensor, scale, zero_point, dtype=torch.int8):\n",
    "    scaled_and_shifted_tensor = tensor / scale + zero_point\n",
    "    \n",
    "    rounded_tensor = torch.round(scaled_and_shifted_tensor)\n",
    "    #最后一步是，确保我们的舍入张量在最小量化值和最大量化值之间\n",
    "    q_min = torch.iinfo(dtype).min#iInfo方法获取最小值和最大值\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "\n",
    "    q_tensor = rounded_tensor.clamp(q_min, q_max).to(dtype)#定义量化张量（使用to()函数转换为我们想要的量化数据类型）\n",
    "    return q_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ca473fa-70cf-431a-a216-79d7a9ca8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_dequantization(quantized_tensor, scale, zero_point):\n",
    "    return scale * (quantized_tensor.float() - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de9fb3fa-83d1-4beb-8902-22313c666f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric(tensor, dtype = torch.int8):\n",
    "    scale = get_q_scale_symmetric(tensor, dtype)\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(tensor, scale, zero_point = 0, dtype=dtype)\n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af7d5f5e-342b-4b1e-8e23-a5bd1363c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor, scale = get_q_symmetric(test_tensor, dtype = torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "890b51b8-335d-4946-8900-de2d85b297b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor, scale, zero_point=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e7be869-ebf0-4b0f-ba00-2f00d1a20d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2690, -0.6340, -0.8069, -0.2113],\n",
       "        [-0.2690,  0.5571,  0.1345, -0.5956],\n",
       "        [ 2.4399,  0.6532, -0.0576, -0.2305],\n",
       "        [-1.3064, -0.5379,  0.7493,  0.2305]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d72a8c8-5162-4801-af95-3562dc830623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_error(original_tensor, dequantized_tensor, error_type=\"mse\"):\n",
    "    \"\"\"\n",
    "    计算量化误差的通用函数（支持 PyTorch 和 NumPy 张量）\n",
    "    \n",
    "    参数：\n",
    "        original_tensor      : 原始浮点张量 (torch.Tensor/np.ndarray)\n",
    "        dequantized_tensor   : 反量化后的重建张量 (与原始张量同类型同形状)\n",
    "        error_type          : 误差计算方式，可选 \"mse\"(默认) 或 \"mae\"\n",
    "    \n",
    "    返回：\n",
    "        量化误差值 (float)\n",
    "    \"\"\"\n",
    "    # 校验输入类型一致性\n",
    "    if type(original_tensor) != type(dequantized_tensor):\n",
    "        raise TypeError(\"原始张量与反量化张量类型必须一致\")\n",
    "\n",
    "    # 校验形状一致性\n",
    "    if original_tensor.shape != dequantized_tensor.shape:\n",
    "        raise ValueError(\"张量形状不匹配\")\n",
    "\n",
    "    # 自动检测计算框架\n",
    "    if isinstance(original_tensor, torch.Tensor):\n",
    "        lib = torch\n",
    "    elif isinstance(original_tensor, np.ndarray):\n",
    "        lib = np\n",
    "    else:\n",
    "        raise TypeError(\"仅支持 PyTorch 或 NumPy 张量\")\n",
    "\n",
    "    # 计算误差\n",
    "    diff = original_tensor - dequantized_tensor\n",
    "    if error_type == \"mse\":\n",
    "        error = lib.mean(diff ** 2)\n",
    "    elif error_type == \"mae\":\n",
    "        error = lib.mean(lib.abs(diff))\n",
    "    else:\n",
    "        raise ValueError(\"error_type 必须为 'mse' 或 'mae'\")\n",
    "\n",
    "    # 返回标量值\n",
    "    return error.item() if lib == torch else float(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73534927-2d5c-4a85-8548-0fe65f4da42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = quantization_error(test_tensor, dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46b47a3f-0135-49d4-9c92-565a025d62fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0263228836702183e-05"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e5e6b-6ee9-498f-a97c-6626a3a4fbee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
